"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

def resolve_disagreement(question, expert_ratings):
    """
    Comprehensive conflict resolution workflow.

    Args:
        question: The question being rated
        expert_ratings: [
            {"expert": "A", "answer": "...", "confidence": 0.9, "quality": 5},
            {"expert": "B", "answer": "...", "confidence": 0.7, "quality": 4},
            {"expert": "C", "answer": "...", "confidence": 0.8, "quality": 5}
        ]

    Returns:
        Resolved example or list of context-specific examples
    """

    # Step 1: Check if consensus exists
    answers = [r["answer"] for r in expert_ratings]
    if len(set(answers)) == 1:
        print("âœ… Perfect consensus - no conflict")
        return {
            "question": question,
            "answer": answers[0],
            "confidence": np.mean([r["confidence"] for r in expert_ratings]),
            "metadata": {"agreement": "unanimous"}
        }

    # Step 2: Calculate confidence delta
    confidences = [r["confidence"] for r in expert_ratings]
    confidence_delta = max(confidences) - min(confidences)

    # Step 3: Route to appropriate resolution strategy
    if confidence_delta > 0.3:
        # Large confidence gap - use confidence weighting
        print("Using confidence weighting (large gap)")
        return resolve_with_confidence_weighting(
            [(r["answer"], r["confidence"]) for r in expert_ratings]
        )

    elif is_factual_question(question):
        # Factual disagreement - use tie-breaker
        print("Using tie-breaker (factual disagreement)")
        return resolve_with_tiebreaker(
            question,
            expert_ratings[0]["answer"],
            expert_ratings[1]["answer"],
            expert_ratings[0]["confidence"],
            expert_ratings[1]["confidence"]
        )

    elif is_tactical_question(question):
        # Tactical disagreement - create context-specific examples
        print("Creating context-specific examples (tactical disagreement)")
        return resolve_with_context(question, answers)

    else:
        # Unresolvable - flag for review
        print("Flagging for senior review")
        return flag_for_review(
            question,
            [(r["answer"], r["confidence"]) for r in expert_ratings],
            reason="Complex disagreement requiring senior expert review"
        )

def is_factual_question(question):
    """Check if question is factual (has one correct answer)."""
    factual_keywords = ["what is", "idlh", "temperature", "pressure", "regulation", "law"]
    return any(kw in question.lower() for kw in factual_keywords)

def is_tactical_question(question):
    """Check if question is tactical (multiple valid approaches)."""
    tactical_keywords = ["should", "evacuate or", "defend or", "priority", "resource allocation"]
    return any(kw in question.lower() for kw in tactical_keywords)
