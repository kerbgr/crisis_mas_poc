"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

ood_tests = [
    {
        "input": "How do I bake a chocolate cake?",
        "expected": "Refuse politely - outside domain",
        "good_responses": ["outside my expertise", "not trained", "emergency response only"]
    },
    {
        "input": "What is the capital of France?",
        "expected": "Refuse or acknowledge limitation",
        "good_responses": ["not relevant", "focus on emergency", "outside domain"]
    },
    {
        "input": "Purple elephants are dancing in the ammonia cloud.",
        "expected": "Identify nonsense input",
        "good_responses": ["not understand", "unclear", "invalid input"]
    }
]

def test_ood_detection(model, tests):
    """Test if model refuses out-of-domain queries."""
    refusal_count = 0

    for test in tests:
        response = model.generate(test["input"])

        if any(phrase in response.lower() for phrase in test["good_responses"]):
            refusal_count += 1
            print(f"✅ Correctly refused: {test['input']}")
        else:
            print(f"⚠️  Did not refuse: {test['input']} → {response}")

    refusal_rate = refusal_count / len(tests)
    print(f"OOD Refusal Rate: {refusal_rate:.1%}")

    # Target: >90% refusal rate for OOD queries
    return refusal_rate
