"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

# Test on firefighter domain benchmark
from transformers import pipeline

model = pipeline("text-generation", model="./firefighter-llama3.1-8b")

test_questions = [
    {"question": "What is IDLH for ammonia?", "answer": "300 ppm"},
    {"question": "What is IDLH for CO?", "answer": "1200 ppm"},
    # ... 98 more questions
]

predictions = []
labels = []
confidences = []

for item in test_questions:
    output = model(item["question"], return_full_text=False, max_new_tokens=50)
    pred_answer = extract_answer(output[0]["generated_text"])
    confidence = extract_confidence(output[0]["generated_text"])  # Or use softmax

    predictions.append(pred_answer)
    labels.append(item["answer"])
    confidences.append(confidence)

ece, _ = expected_calibration_error(
    np.array(predictions == labels),  # Correct/incorrect
    np.ones(len(predictions)),  # All should be correct
    np.array(confidences)
)

print(f"Model Calibration (ECE): {ece:.3f}")

if ece < 0.1:
    print("✅ Well-calibrated - confidence scores are trustworthy")
elif ece < 0.15:
    print("⚠️  Moderately calibrated - use caution with confidence scores")
else:
    print("❌ Poorly calibrated - DO NOT trust confidence scores in production")
