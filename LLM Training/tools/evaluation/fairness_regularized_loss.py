"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

def fairness_regularized_loss(model_output, target, protected_group):
    """
    Add fairness constraint to training loss.
    Penalize model if accuracy differs significantly across groups.
    """
    # Standard cross-entropy loss
    ce_loss = cross_entropy(model_output, target)

    # Calculate per-group accuracy
    group_a_mask = (protected_group == "urban")
    group_b_mask = (protected_group == "rural")

    acc_a = accuracy(model_output[group_a_mask], target[group_a_mask])
    acc_b = accuracy(model_output[group_b_mask], target[group_b_mask])

    # Fairness penalty (penalize large accuracy gaps)
    fairness_penalty = abs(acc_a - acc_b)

    # Combined loss
    total_loss = ce_loss + 0.1 * fairness_penalty

    return total_loss
