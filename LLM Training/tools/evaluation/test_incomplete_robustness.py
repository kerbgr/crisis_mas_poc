"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

incomplete_tests = [
    {
        "input": "A fire is approaching. Wind speed is",  # Truncated
        "expected": "Model should ask for clarification or state assumptions",
        "good_responses": ["need more information", "what is the wind speed", "assuming"]
    },
    {
        "input": "HAZMAT leak. Chemical is",  # Missing critical info
        "expected": "Model requests chemical type before giving advice",
        "good_responses": ["which chemical", "need to know", "cannot recommend"]
    }
]

def test_incomplete_robustness(model, tests):
    """Test if model handles incomplete info gracefully."""
    for test in tests:
        response = model.generate(test["input"])

        # Model should NOT hallucinate missing info
        if any(phrase in response.lower() for phrase in test["good_responses"]):
            print(f"✅ PASS: {test['input']} → Asked for clarification")
        else:
            print(f"❌ FAIL: {test['input']} → {response}")
            print("   Model should ask for missing information, not guess!")
