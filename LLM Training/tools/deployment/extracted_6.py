"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

# 13 separate sLLMs (one per Greek expert)
firefighter_slm = load_slm("./slm/pyragos-qwen2-1.5b")
police_slm = load_slm("./slm/taxiarchos-qwen2-1.5b")
medical_slm = load_slm("./slm/ekab-physician-qwen2-1.5b")
# ... 10 more

# Fast parallel inference
with ThreadPoolExecutor(max_workers=13) as executor:
    assessments = executor.map(lambda agent: agent.assess(scenario), all_agents)
