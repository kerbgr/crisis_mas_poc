"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

class DataDriftDetector:
    """Detect when input distribution changes."""

    def __init__(self, model):
        self.model = model
        self.tokenizer = tokenizer
        self.reference_embeddings = self._compute_reference_embeddings()
        self.drift_threshold = 0.25  # Alert if distance > 0.25

    def _compute_reference_embeddings(self):
        """Compute embeddings for training data distribution."""
        # Sample 1000 examples from training data
        with open("training_sample.json", "r") as f:
            training_data = json.load(f)

        embeddings = []
        for item in training_data[:1000]:
            emb = self._get_embedding(item["input"])
            embeddings.append(emb)

        # Average embedding (centroid)
        reference_centroid = np.mean(embeddings, axis=0)

        return {"centroid": reference_centroid, "embeddings": embeddings}

    def _get_embedding(self, text: str):
        """Get embedding for text using model."""
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
        with torch.no_grad():
            outputs = self.model(**inputs, output_hidden_states=True)
            # Use last hidden state, mean pooling
            embedding = outputs.hidden_states[-1].mean(dim=1).cpu().numpy()[0]
        return embedding

    def check_drift_weekly(self, recent_queries: List[str]):
        """Check if recent queries have drifted from training distribution."""

        print("Running data drift detection...")

        # Get embeddings for recent queries
        recent_embeddings = [self._get_embedding(q) for q in recent_queries]
        recent_centroid = np.mean(recent_embeddings, axis=0)

        # Calculate distance between centroids (cosine distance)
        from scipy.spatial.distance import cosine

        distance = cosine(self.reference_embeddings["centroid"], recent_centroid)

        print(f"Data Drift Distance: {distance:.3f}")

        if distance > self.drift_threshold:
            self._send_drift_alert(distance)
            return True

        return False

    def _send_drift_alert(self, distance):
        """Alert that data drift detected."""
        alert = {
            "type": "data_drift",
            "severity": "warning",
            "message": f"Input distribution has drifted (distance: {distance:.3f})",
            "recommendation": "Analyze recent queries for new patterns. Consider collecting new training data.",
            "timestamp": time.time()
        }

        with open("drift_alerts.jsonl", "a") as f:
            f.write(json.dumps(alert) + "\n")

        send_to_slack(alert)

# Run weekly
data_drift_detector = DataDriftDetector(model)

def check_data_drift():
    # Get last 500 queries
    with open("llm_requests.log", "r") as f:
        recent_queries = [json.loads(line)["messages"][-1]["content"] for line in f.readlines()[-500:]]

    drift_detected = data_drift_detector.check_drift_weekly(recent_queries)
    if drift_detected:
        print("⚠️ DATA DRIFT DETECTED - Input distribution has changed")

schedule.every().monday.at("00:00").do(check_data_drift)
