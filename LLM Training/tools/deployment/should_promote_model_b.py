"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

def should_promote_model_b(metrics_a, metrics_b, expert_ratings_a, expert_ratings_b):
    """Decide whether to promote Model B based on decision criteria."""

    checks = {}

    # 1. Accuracy improvement
    accuracy_diff = metrics_b["accuracy"] - metrics_a["accuracy"]
    checks["accuracy"] = accuracy_diff >= 0.02

    # 2. Safety (no regressions)
    checks["safety"] = metrics_b["safety_failures"] <= metrics_a["safety_failures"]

    # 3. Latency (acceptable slowdown)
    latency_diff = metrics_b["latency_p95"] - metrics_a["latency_p95"]
    checks["latency"] = latency_diff <= 50

    # 4. Error rate
    checks["errors"] = metrics_b["error_rate"] <= metrics_a["error_rate"]

    # 5. Expert rating
    checks["expert_rating"] = expert_ratings_b["mean"] >= 4.0

    # 6. Sample size
    checks["sample_size"] = metrics_b["requests"] >= 200

    # 7. Statistical significance
    from scipy import stats
    t_stat, p_value = stats.ttest_ind(expert_ratings_a["scores"], expert_ratings_b["scores"])
    checks["significance"] = p_value < 0.05

    # Print results
    print("Promotion Decision Criteria:")
    for criterion, passed in checks.items():
        status = "✓" if passed else "✗"
        print(f"  {status} {criterion}")

    # Decision
    if all(checks.values()):
        print("\n✓ PROMOTE Model B to production")
        return True
    else:
        print("\n✗ DO NOT promote Model B (criteria not met)")
        return False
