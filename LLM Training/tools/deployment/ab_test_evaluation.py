"""
Extracted from LLM Training Methodology.
Auto-generated by extract_code_from_methodology.py
"""

# tools/ab_test_evaluation.py

import json
import random

def sample_for_evaluation(log_file, num_samples=100):
    """Sample random requests for expert evaluation."""

    with open(log_file, "r") as f:
        logs = [json.loads(line) for line in f]

    # Sample equally from both models
    model_a_logs = [log for log in logs if log["model"] == "model_a"]
    model_b_logs = [log for log in logs if log["model"] == "model_b"]

    sample_a = random.sample(model_a_logs, num_samples // 2)
    sample_b = random.sample(model_b_logs, num_samples // 2)

    # Create evaluation sheet (CSV)
    with open("ab_test_evaluation.csv", "w") as f:
        f.write("request_id,model,input,output,accuracy_score,safety_score,notes\n")

        for log in sample_a + sample_b:
            f.write(f"{log['request_id']},{log['model']},{log['input']},{log['output']},,,,\n")

    print(f"Created evaluation sheet with {num_samples} samples")
    print("Send ab_test_evaluation.csv to domain experts for scoring")

def analyze_evaluation_results(eval_file="ab_test_evaluation_completed.csv"):
    """Analyze expert ratings."""

    import pandas as pd

    df = pd.read_csv(eval_file)

    # Compare average scores
    results = df.groupby("model").agg({
        "accuracy_score": ["mean", "std"],
        "safety_score": ["mean", "std"]
    })

    print("Expert Evaluation Results:")
    print(results)

    # Statistical significance test
    from scipy import stats

    model_a_scores = df[df["model"] == "model_a"]["accuracy_score"]
    model_b_scores = df[df["model"] == "model_b"]["accuracy_score"]

    t_stat, p_value = stats.ttest_ind(model_a_scores, model_b_scores)

    print(f"\nStatistical Significance:")
    print(f"  t-statistic: {t_stat:.3f}")
    print(f"  p-value: {p_value:.4f}")

    if p_value < 0.05:
        if model_b_scores.mean() > model_a_scores.mean():
            print("  ✓ Model B is SIGNIFICANTLY BETTER (p < 0.05)")
        else:
            print("  ✗ Model B is SIGNIFICANTLY WORSE (p < 0.05)")
    else:
        print("  ≈ No significant difference (p >= 0.05)")

sample_for_evaluation("ab_test_logs.jsonl", num_samples=100)
